{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ae66a0",
   "metadata": {},
   "source": [
    "1. Image classification using SVM with HOG features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6df03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Binary Image Classification using HOG Features and SVM\n",
    "\n",
    "This program classifies images into two classes using:\n",
    "1. HOG (Histogram of Oriented Gradients) feature extraction\n",
    "2. SVM (Support Vector Machine) classification\n",
    "\n",
    "The program loads images from specified directories, extracts HOG features,\n",
    "trains an SVM model, and evaluates its performance with metrics like F1-score.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Image Loading and Preprocessing Functions\n",
    "def load_images(folder_path, label, target_size=(64, 128)):\n",
    "    \"\"\"\n",
    "    Load images from a folder, preprocess them, and assign labels.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing images\n",
    "        label (int): Class label (0 or 1)\n",
    "        target_size (tuple): Size to resize images to\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (images, labels) - list of preprocessed images and their labels\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Get all image files\n",
    "    image_paths = []\n",
    "    for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
    "        image_paths.extend(glob.glob(os.path.join(folder_path, ext)))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"Warning: No images found in {folder_path}\")\n",
    "        return images, labels\n",
    "    \n",
    "    print(f\"Processing {len(image_paths)} images from {folder_path}...\")\n",
    "    \n",
    "    # Process each image\n",
    "    for img_path in image_paths:\n",
    "        try:\n",
    "            # Read image\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not read image {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Convert to grayscale\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Resize image\n",
    "            resized = cv2.resize(gray, target_size)\n",
    "            \n",
    "            # Add to dataset\n",
    "            images.append(resized)\n",
    "            labels.append(label)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {str(e)}\")\n",
    "    \n",
    "    print(f\"Processed {len(images)} images successfully\")\n",
    "    return images, labels\n",
    "\n",
    "# HOG Feature Extraction Function\n",
    "def extract_hog_features(images, orientations=9, pixels_per_cell=(8, 8), \n",
    "                        cells_per_block=(2, 2), block_norm='L2-Hys'):\n",
    "    \"\"\"\n",
    "    Extract HOG features from a list of images.\n",
    "    \n",
    "    Args:\n",
    "        images (list): List of grayscale images\n",
    "        orientations (int): Number of orientation bins for HOG\n",
    "        pixels_per_cell (tuple): Size of a cell in pixels\n",
    "        cells_per_block (tuple): Number of cells in each block\n",
    "        block_norm (str): Block normalization method\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: HOG features for all images\n",
    "    \"\"\"\n",
    "    hog_features = []\n",
    "    \n",
    "    print(\"Extracting HOG features...\")\n",
    "    for img in images:\n",
    "        features = hog(\n",
    "            img,\n",
    "            orientations=orientations,\n",
    "            pixels_per_cell=pixels_per_cell,\n",
    "            cells_per_block=cells_per_block,\n",
    "            block_norm=block_norm,\n",
    "            visualize=False\n",
    "        )\n",
    "        hog_features.append(features)\n",
    "    \n",
    "    print(f\"Extracted HOG features from {len(hog_features)} images\")\n",
    "    return np.array(hog_features)\n",
    "\n",
    "# Visualize HOG features for a sample image\n",
    "def visualize_hog(image, orientations=9, pixels_per_cell=(8, 8), \n",
    "                 cells_per_block=(2, 2), block_norm='L2-Hys'):\n",
    "    \"\"\"\n",
    "    Visualize HOG features for a single image.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): Grayscale image\n",
    "        orientations (int): Number of orientation bins for HOG\n",
    "        pixels_per_cell (tuple): Size of a cell in pixels\n",
    "        cells_per_block (tuple): Number of cells in each block\n",
    "        block_norm (str): Block normalization method\n",
    "    \"\"\"\n",
    "    features, hog_image = hog(\n",
    "        image,\n",
    "        orientations=orientations,\n",
    "        pixels_per_cell=pixels_per_cell,\n",
    "        cells_per_block=cells_per_block,\n",
    "        block_norm=block_norm,\n",
    "        visualize=True\n",
    "    )\n",
    "    \n",
    "    # Display original and HOG image\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax1.imshow(image, cmap='gray')\n",
    "    ax1.set_title('Original Image (Grayscale)')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(hog_image, cmap='gray')\n",
    "    ax2.set_title('HOG Visualization')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"HOG feature vector shape: {features.shape}\")\n",
    "    return features\n",
    "\n",
    "# SVM Training Function\n",
    "def train_svm(X_train, y_train, kernel='rbf', C=1.0, gamma='scale', probability=True):\n",
    "    \"\"\"\n",
    "    Train an SVM model.\n",
    "    \n",
    "    Args:\n",
    "        X_train (numpy.ndarray): Training features\n",
    "        y_train (numpy.ndarray): Training labels\n",
    "        kernel (str): Kernel type ('linear', 'rbf', 'poly', etc.)\n",
    "        C (float): Regularization parameter\n",
    "        gamma (str/float): Kernel coefficient for 'rbf', 'poly', 'sigmoid'\n",
    "        probability (bool): Enable probability estimates\n",
    "        \n",
    "    Returns:\n",
    "        SVC: Trained SVM model\n",
    "    \"\"\"\n",
    "    print(f\"Training SVM with kernel={kernel}, C={C}, gamma={gamma}...\")\n",
    "    \n",
    "    # Create and train SVM model\n",
    "    model = SVC(\n",
    "        kernel=kernel,\n",
    "        C=C,\n",
    "        gamma=gamma,\n",
    "        probability=probability,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"SVM model trained successfully\")\n",
    "    return model\n",
    "\n",
    "# Model Evaluation Function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model and display performance metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained classification model\n",
    "        X_test (numpy.ndarray): Test features\n",
    "        y_test (numpy.ndarray): Test labels\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Print evaluation results\n",
    "    print(\"\\nModel Evaluation Results:\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=['Class 0', 'Class 1'],\n",
    "               yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to perform the image classification process.\n",
    "    \"\"\"\n",
    "    print(\"Binary Image Classification using HOG Features and SVM\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Directory paths\n",
    "    print(\"\\nLoading image directories:\")\n",
    "    train_path_class1 = \"./resources/classification/cats\"\n",
    "    train_path_class2 = \"./resources/classification/dogs\"\n",
    "    test_path_class1 = \"./resources/classification/cat_test\"\n",
    "    test_path_class2 = \"./resources/classification/dog_test\"\n",
    "    \n",
    "    # Validate paths\n",
    "    for path in [train_path_class1, train_path_class2, test_path_class1, test_path_class2]:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Error: Path {path} does not exist!\")\n",
    "            return\n",
    "    \n",
    "    # Set HOG parameters\n",
    "    target_size = (64, 128)\n",
    "    hog_params = {\n",
    "        'orientations': 9,\n",
    "        'pixels_per_cell': (8, 8),\n",
    "        'cells_per_block': (2, 2),\n",
    "        'block_norm': 'L2-Hys'\n",
    "    }\n",
    "    \n",
    "    # Load and preprocess images\n",
    "    print(\"\\nStep 1: Loading and preprocessing images...\")\n",
    "    train_images_class1, train_labels_class1 = load_images(train_path_class1, 0, target_size)\n",
    "    train_images_class2, train_labels_class2 = load_images(train_path_class2, 1, target_size)\n",
    "    test_images_class1, test_labels_class1 = load_images(test_path_class1, 0, target_size)\n",
    "    test_images_class2, test_labels_class2 = load_images(test_path_class2, 1, target_size)\n",
    "    \n",
    "    # Combine datasets\n",
    "    train_images = train_images_class1 + train_images_class2\n",
    "    train_labels = train_labels_class1 + train_labels_class2\n",
    "    test_images = test_images_class1 + test_images_class2\n",
    "    test_labels = test_labels_class1 + test_labels_class2\n",
    "    \n",
    "    # Visualize HOG features for a sample image (optional)\n",
    "    if train_images:\n",
    "        print(\"\\nStep 2: Visualizing HOG features for a sample image...\")\n",
    "        visualize_hog(train_images[0], **hog_params)\n",
    "    \n",
    "    # Extract HOG features\n",
    "    print(\"\\nStep 3: Extracting HOG features...\")\n",
    "    X_train = extract_hog_features(train_images, **hog_params)\n",
    "    X_test = extract_hog_features(test_images, **hog_params)\n",
    "    y_train = np.array(train_labels)\n",
    "    y_test = np.array(test_labels)\n",
    "    \n",
    "    # Normalize features using StandardScaler\n",
    "    print(\"\\nStep 4: Normalizing features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Print dataset shapes\n",
    "    print(f\"\\nTraining data: {X_train_scaled.shape}, Labels: {y_train.shape}\")\n",
    "    print(f\"Testing data: {X_test_scaled.shape}, Labels: {y_test.shape}\")\n",
    "    \n",
    "    # Train SVM model\n",
    "    print(\"\\nStep 5: Training SVM model...\")\n",
    "    svm_model = train_svm(X_train_scaled, y_train, kernel='linear', C=1.0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(\"\\nStep 6: Evaluating the model...\")\n",
    "    metrics = evaluate_model(svm_model, X_test_scaled, y_test)\n",
    "    \n",
    "    print(\"\\nBinary Image Classification process completed!\")\n",
    "    print(f\"Final F1-Score: {metrics['f1']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f207eaf",
   "metadata": {},
   "source": [
    "2. Image classification using SVM with SIFT descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53407c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Binary Image Classification using SIFT Features and SVM\n",
    "\n",
    "This program classifies images into two classes by:\n",
    "1. Extracting SIFT descriptors from images\n",
    "2. Normalizing the number of descriptors (padding/truncating)\n",
    "3. Flattening descriptors into feature vectors\n",
    "4. Training an SVM model for classification\n",
    "5. Evaluating model performance using metrics like F1-score\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Number of SIFT keypoints to use per image (fixed size)\n",
    "N_KEYPOINTS = 100\n",
    "\n",
    "# Image Loading and Preprocessing Functions\n",
    "def load_images(folder_path, label):\n",
    "    \"\"\"\n",
    "    Load images from a folder and assign labels.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing images\n",
    "        label (int): Class label (0 or 1)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (image_paths, labels) - list of image paths and their labels\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # Get all image files\n",
    "    for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
    "        image_paths.extend(glob.glob(os.path.join(folder_path, ext)))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"Warning: No images found in {folder_path}\")\n",
    "        return image_paths, labels\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images in {folder_path}\")\n",
    "    \n",
    "    # Assign labels\n",
    "    labels = [label] * len(image_paths)\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "# SIFT Feature Extraction Functions\n",
    "def extract_sift_features(image_path, n_keypoints=N_KEYPOINTS):\n",
    "    \"\"\"\n",
    "    Extract SIFT features from a single image and normalize to a fixed number of keypoints.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        n_keypoints (int): Number of keypoints to extract/normalize to\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Normalized SIFT descriptors (n_keypoints x 128)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image {image_path}\")\n",
    "            # Return zeros if image cannot be read\n",
    "            return np.zeros((n_keypoints, 128))\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Create SIFT detector\n",
    "        sift = cv2.SIFT_create()\n",
    "        \n",
    "        # Detect keypoints and compute descriptors\n",
    "        keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "        \n",
    "        # Handle case where no keypoints are found\n",
    "        if descriptors is None or len(descriptors) == 0:\n",
    "            print(f\"Warning: No SIFT keypoints found in {image_path}\")\n",
    "            return np.zeros((n_keypoints, 128))\n",
    "        \n",
    "        # Normalize number of keypoints\n",
    "        if len(descriptors) < n_keypoints:\n",
    "            # Pad with zeros\n",
    "            padding = np.zeros((n_keypoints - len(descriptors), 128))\n",
    "            normalized_descriptors = np.vstack([descriptors, padding])\n",
    "        else:\n",
    "            # Truncate to first n_keypoints\n",
    "            normalized_descriptors = descriptors[:n_keypoints]\n",
    "        \n",
    "        return normalized_descriptors\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        # Return zeros in case of error\n",
    "        return np.zeros((n_keypoints, 128))\n",
    "\n",
    "def process_image_dataset(image_paths, labels, n_keypoints=N_KEYPOINTS):\n",
    "    \"\"\"\n",
    "    Process a dataset of images to extract and normalize SIFT features.\n",
    "    \n",
    "    Args:\n",
    "        image_paths (list): List of image file paths\n",
    "        labels (list): List of labels corresponding to each image\n",
    "        n_keypoints (int): Number of keypoints to extract/normalize to\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (features, labels) - SIFT features and corresponding labels\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    processed_labels = []\n",
    "    \n",
    "    print(f\"Extracting SIFT features from {len(image_paths)} images...\")\n",
    "    \n",
    "    for i, (path, label) in enumerate(zip(image_paths, labels)):\n",
    "        # Extract and normalize SIFT features\n",
    "        descriptors = extract_sift_features(path, n_keypoints)\n",
    "        \n",
    "        # Flatten the descriptors to a 1D array\n",
    "        flat_descriptors = descriptors.flatten()\n",
    "        \n",
    "        # Add to dataset\n",
    "        features.append(flat_descriptors)\n",
    "        processed_labels.append(label)\n",
    "        \n",
    "        # Print progress\n",
    "        if (i+1) % 10 == 0 or i+1 == len(image_paths):\n",
    "            print(f\"Processed {i+1}/{len(image_paths)} images\")\n",
    "    \n",
    "    return np.array(features), np.array(processed_labels)\n",
    "\n",
    "# Visualize SIFT keypoints for a sample image\n",
    "def visualize_sift(image_path):\n",
    "    \"\"\"\n",
    "    Visualize SIFT keypoints for a single image.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image {image_path}\")\n",
    "            return\n",
    "        \n",
    "        # Convert to grayscale for SIFT\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Create SIFT detector\n",
    "        sift = cv2.SIFT_create()\n",
    "        \n",
    "        # Detect keypoints\n",
    "        keypoints = sift.detect(gray, None)\n",
    "        \n",
    "        # Draw keypoints\n",
    "        img_keypoints = cv2.drawKeypoints(gray, keypoints, None, \n",
    "                                         flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        \n",
    "        # Display original and keypoints\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.imshow(img_keypoints)\n",
    "        plt.title(f'SIFT Keypoints: {len(keypoints)} detected')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Total SIFT keypoints detected: {len(keypoints)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing SIFT keypoints: {str(e)}\")\n",
    "\n",
    "# SVM Training and Evaluation Functions\n",
    "def train_svm(X_train, y_train, kernel='linear', C=1.0, gamma='scale'):\n",
    "    \"\"\"\n",
    "    Train an SVM model.\n",
    "    \n",
    "    Args:\n",
    "        X_train (numpy.ndarray): Training features\n",
    "        y_train (numpy.ndarray): Training labels\n",
    "        kernel (str): Kernel type ('linear', 'rbf', 'poly', etc.)\n",
    "        C (float): Regularization parameter\n",
    "        gamma (str/float): Kernel coefficient for 'rbf', 'poly', 'sigmoid'\n",
    "        \n",
    "    Returns:\n",
    "        SVC: Trained SVM model\n",
    "    \"\"\"\n",
    "    print(f\"Training SVM with kernel={kernel}, C={C}, gamma={gamma}...\")\n",
    "    \n",
    "    # Create and train SVM model\n",
    "    model = SVC(\n",
    "        kernel=kernel,\n",
    "        C=C,\n",
    "        gamma=gamma,\n",
    "        probability=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"SVM model trained successfully\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model and display performance metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained classification model\n",
    "        X_test (numpy.ndarray): Test features\n",
    "        y_test (numpy.ndarray): Test labels\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Print evaluation results\n",
    "    print(\"\\nModel Evaluation Results:\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=['Class 0', 'Class 1'],\n",
    "               yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to perform the image classification process.\n",
    "    \"\"\"\n",
    "    print(\"Binary Image Classification using SIFT Features and SVM\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Directory paths\n",
    "    print(\"\\nLoading image directories:\")\n",
    "    train_path_class1 = \"./resources/classification/cats\"\n",
    "    train_path_class2 = \"./resources/classification/dogs\"\n",
    "    test_path_class1 = \"./resources/classification/cat_test\"\n",
    "    test_path_class2 = \"./resources/classification/dog_test\"\n",
    "    \n",
    "    # Validate paths\n",
    "    for path in [train_path_class1, train_path_class2, test_path_class1, test_path_class2]:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Error: Path {path} does not exist!\")\n",
    "            return\n",
    "    \n",
    "    # Set SIFT and SVM parameters\n",
    "    n_keypoints = N_KEYPOINTS\n",
    "    svm_params = {\n",
    "        'kernel': 'linear',\n",
    "        'C': 1.0,\n",
    "        'gamma': 'scale'\n",
    "    }\n",
    "    \n",
    "    # Step 1: Load image paths and labels\n",
    "    print(\"\\nStep 1: Loading images and labels...\")\n",
    "    train_paths_class1, train_labels_class1 = load_images(train_path_class1, 0)\n",
    "    train_paths_class2, train_labels_class2 = load_images(train_path_class2, 1)\n",
    "    test_paths_class1, test_labels_class1 = load_images(test_path_class1, 0)\n",
    "    test_paths_class2, test_labels_class2 = load_images(test_path_class2, 1)\n",
    "    \n",
    "    # Combine datasets\n",
    "    train_paths = train_paths_class1 + train_paths_class2\n",
    "    train_labels = train_labels_class1 + train_labels_class2\n",
    "    test_paths = test_paths_class1 + test_paths_class2\n",
    "    test_labels = test_labels_class1 + test_labels_class2\n",
    "    \n",
    "    # Optional: Visualize SIFT keypoints for a sample image\n",
    "    if train_paths:\n",
    "        print(\"\\nStep 2: Visualizing SIFT keypoints for a sample image...\")\n",
    "        visualize_sift(train_paths[0])\n",
    "    \n",
    "    # Step 3: Extract SIFT features\n",
    "    print(\"\\nStep 3: Extracting SIFT features...\")\n",
    "    X_train, y_train = process_image_dataset(train_paths, train_labels, n_keypoints)\n",
    "    X_test, y_test = process_image_dataset(test_paths, test_labels, n_keypoints)\n",
    "    \n",
    "    print(f\"\\nFeature vector shape: {X_train.shape[1]} dimensions\")\n",
    "    \n",
    "    # Step 4: Normalize features using StandardScaler\n",
    "    print(\"\\nStep 4: Normalizing features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Print dataset shapes\n",
    "    print(f\"\\nTraining data: {X_train_scaled.shape}, Labels: {y_train.shape}\")\n",
    "    print(f\"Testing data: {X_test_scaled.shape}, Labels: {y_test.shape}\")\n",
    "    \n",
    "    # Step 5: Train SVM model\n",
    "    print(\"\\nStep 5: Training SVM model...\")\n",
    "    svm_model = train_svm(X_train_scaled, y_train, **svm_params)\n",
    "    \n",
    "    # Step 6: Evaluate the model\n",
    "    print(\"\\nStep 6: Evaluating the model...\")\n",
    "    metrics = evaluate_model(svm_model, X_test_scaled, y_test)\n",
    "    \n",
    "    print(\"\\nBinary Image Classification process completed!\")\n",
    "    print(f\"Final F1-Score: {metrics['f1']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728fa88",
   "metadata": {},
   "source": [
    "2. Image classification using ANN with SIFT descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1df5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Binary Image Classification using SIFT, Bag of Visual Words, and ANN (MLPClassifier)\n",
    "\n",
    "This program classifies images into two classes by:\n",
    "1. Extracting SIFT descriptors from all images\n",
    "2. Building a visual vocabulary using K-means clustering\n",
    "3. Creating histogram representations (BoVW) for each image\n",
    "4. Training an Artificial Neural Network for classification\n",
    "5. Evaluating model performance using metrics like F1-score and confusion matrix\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SIFT Feature Extraction Functions\n",
    "def extract_sift_descriptors(image_path):\n",
    "    \"\"\"\n",
    "    Extract SIFT descriptors from a single image.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        list or None: List of SIFT descriptors or None if no keypoints found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Create SIFT detector\n",
    "        sift = cv2.SIFT_create(nfeatures = 200)\n",
    "        \n",
    "        # Detect keypoints and compute descriptors\n",
    "        keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "        \n",
    "        return descriptors\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_images_and_extract_sift(folder_path, label):\n",
    "    \"\"\"\n",
    "    Extract SIFT descriptors from all images in a folder and create labels.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing images\n",
    "        label (int): Class label (0 or 1)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (all_descriptors, image_descriptors, labels)\n",
    "            - all_descriptors: flattened list of all descriptors\n",
    "            - image_descriptors: list of descriptors per image\n",
    "            - labels: list of labels corresponding to each image\n",
    "    \"\"\"\n",
    "    all_descriptors = []  # Will contain all descriptors from all images\n",
    "    image_descriptors = []  # Will contain descriptors per image\n",
    "    labels = []  # Will contain labels for each image\n",
    "    \n",
    "    # Get all image files in the folder\n",
    "    image_paths = []\n",
    "    for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
    "        image_paths.extend(glob.glob(os.path.join(folder_path, ext)))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"Warning: No images found in {folder_path}\")\n",
    "        return [], [], []\n",
    "    \n",
    "    print(f\"Processing {len(image_paths)} images from {folder_path}...\")\n",
    "    \n",
    "    # Process each image\n",
    "    for img_path in image_paths:\n",
    "        descriptors = extract_sift_descriptors(img_path)\n",
    "        \n",
    "        if descriptors is not None and descriptors.shape[0] > 0:\n",
    "            all_descriptors.append(descriptors)\n",
    "            image_descriptors.append(descriptors)\n",
    "            labels.append(label)\n",
    "    \n",
    "    # Flatten all_descriptors for K-means clustering\n",
    "    if all_descriptors:\n",
    "        all_descriptors = np.vstack(all_descriptors)\n",
    "    \n",
    "    print(f\"Extracted {len(all_descriptors)} SIFT descriptors from {len(image_descriptors)} images\")\n",
    "    return all_descriptors, image_descriptors, labels\n",
    "\n",
    "# Visual Vocabulary Building Functions\n",
    "def plot_elbow_method(all_train_descriptors, max_k=20):\n",
    "    \"\"\"\n",
    "    Plot the Elbow Method graph to help determine optimal number of clusters.\n",
    "    \n",
    "    Args:\n",
    "        all_train_descriptors (numpy.ndarray): All SIFT descriptors from training set\n",
    "        max_k (int): Maximum number of clusters to try\n",
    "    \"\"\"\n",
    "    # Use a sample if there are too many descriptors\n",
    "    if len(all_train_descriptors) > 10000:\n",
    "        print(\"Sampling descriptors for elbow method...\")\n",
    "        indices = np.random.choice(len(all_train_descriptors), 10000, replace=False)\n",
    "        sample_descriptors = all_train_descriptors[indices]\n",
    "    else:\n",
    "        sample_descriptors = all_train_descriptors\n",
    "    \n",
    "    wcss = []  # Within-cluster sum of squares\n",
    "    k_values = range(1, max_k + 1)\n",
    "    \n",
    "    print(\"Calculating WCSS for different K values...\")\n",
    "    for k in k_values:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(sample_descriptors)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "        print(f\"K={k}, WCSS={kmeans.inertia_:.2f}\")\n",
    "    \n",
    "    # Plot the Elbow graph\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_values, wcss, 'bo-')\n",
    "    plt.xlabel('Number of Clusters (K)')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.title('Elbow Method For Optimal K')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def build_visual_vocabulary(all_train_descriptors, num_clusters):\n",
    "    \"\"\"\n",
    "    Build a visual vocabulary by clustering SIFT descriptors.\n",
    "    \n",
    "    Args:\n",
    "        all_train_descriptors (numpy.ndarray): All SIFT descriptors from training set\n",
    "        num_clusters (int): Number of clusters (size of vocabulary)\n",
    "        \n",
    "    Returns:\n",
    "        KMeans: Trained K-means model\n",
    "    \"\"\"\n",
    "    print(f\"Building visual vocabulary with K={num_clusters}...\")\n",
    "    \n",
    "    # Sample descriptors if there are too many\n",
    "    if len(all_train_descriptors) > 100000:\n",
    "        print(\"Sampling descriptors for K-means clustering...\")\n",
    "        indices = np.random.choice(len(all_train_descriptors), 100000, replace=False)\n",
    "        sample_descriptors = all_train_descriptors[indices]\n",
    "    else:\n",
    "        sample_descriptors = all_train_descriptors\n",
    "    \n",
    "    # Create and train K-means model\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "    kmeans.fit(sample_descriptors)\n",
    "    \n",
    "    print(\"Visual vocabulary built successfully\")\n",
    "    return kmeans\n",
    "\n",
    "# Bag of Visual Words Functions\n",
    "def create_bovw_histograms(image_descriptors, kmeans_model):\n",
    "    \"\"\"\n",
    "    Create a Bag of Visual Words histogram for a single image.\n",
    "    \n",
    "    Args:\n",
    "        image_descriptors (numpy.ndarray): SIFT descriptors for one image\n",
    "        kmeans_model (KMeans): Trained K-means model\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Normalized histogram of visual words\n",
    "    \"\"\"\n",
    "    # If no descriptors were found, return zeros\n",
    "    if image_descriptors is None or len(image_descriptors) == 0:\n",
    "        return np.zeros(kmeans_model.n_clusters)\n",
    "    \n",
    "    # Predict the closest cluster for each descriptor\n",
    "    visual_words = kmeans_model.predict(image_descriptors)\n",
    "    \n",
    "    # Create histogram of visual words\n",
    "    histogram = np.zeros(kmeans_model.n_clusters)\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    \n",
    "    # Normalize the histogram (L2 normalization)\n",
    "    norm = np.linalg.norm(histogram)\n",
    "    if norm > 0:\n",
    "        histogram = histogram / norm\n",
    "    \n",
    "    return histogram\n",
    "\n",
    "def process_image_folder_to_bovw(folder_path, label, kmeans_model):\n",
    "    \"\"\"\n",
    "    Process all images in a folder to create BoVW representations.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing images\n",
    "        label (int): Class label (0 or 1)\n",
    "        kmeans_model (KMeans): Trained K-means model\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (features, labels)\n",
    "            - features: BoVW histograms for all images\n",
    "            - labels: Labels for all images\n",
    "    \"\"\"\n",
    "    # Extract SIFT descriptors\n",
    "    _, image_descriptors_list, image_labels = load_images_and_extract_sift(folder_path, label)\n",
    "    \n",
    "    # Create BoVW histograms for each image\n",
    "    bovw_features = []\n",
    "    for descriptors in image_descriptors_list:\n",
    "        histogram = create_bovw_histograms(descriptors, kmeans_model)\n",
    "        bovw_features.append(histogram)\n",
    "    \n",
    "    if bovw_features:\n",
    "        bovw_features = np.array(bovw_features)\n",
    "        image_labels = np.array(image_labels)\n",
    "    else:\n",
    "        bovw_features = np.array([])\n",
    "        image_labels = np.array([])\n",
    "    \n",
    "    print(f\"Created {len(bovw_features)} BoVW histograms from {folder_path}\")\n",
    "    return bovw_features, image_labels\n",
    "\n",
    "# ANN Model Functions\n",
    "def create_and_train_ann_model(X_train, y_train, mlp_params=None):\n",
    "    \"\"\"\n",
    "    Create and train an Artificial Neural Network model using MLPClassifier.\n",
    "    \n",
    "    Args:\n",
    "        X_train (numpy.ndarray): Training features (BoVW histograms)\n",
    "        y_train (numpy.ndarray): Training labels\n",
    "        mlp_params (dict): Parameters for MLPClassifier\n",
    "        \n",
    "    Returns:\n",
    "        MLPClassifier: Trained ANN model\n",
    "    \"\"\"\n",
    "    # Set default parameters if none provided\n",
    "    if mlp_params is None:\n",
    "        mlp_params = {\n",
    "            'hidden_layer_sizes': (64, 32),\n",
    "            'activation': 'relu',\n",
    "            'solver': 'adam',\n",
    "            'alpha': 0.0001,\n",
    "            'max_iter': 300,\n",
    "            'batch_size': 'auto',\n",
    "            'learning_rate_init': 0.001,\n",
    "            'early_stopping': True,\n",
    "            'validation_fraction': 0.1,\n",
    "            'random_state': 42\n",
    "        }\n",
    "    \n",
    "    print(\"Creating and training MLPClassifier...\")\n",
    "    print(f\"Parameters: {mlp_params}\")\n",
    "    \n",
    "    # Create MLP model\n",
    "    model = MLPClassifier(**mlp_params)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"MLPClassifier trained successfully\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate the model performance.\n",
    "    \n",
    "    Args:\n",
    "        y_true (numpy.ndarray): Ground truth labels\n",
    "        y_pred (numpy.ndarray): Predicted labels\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    # Print evaluation results\n",
    "    print(\"\\nModel Evaluation Results:\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, ['Class 0', 'Class 1'], rotation=45)\n",
    "    plt.yticks(tick_marks, ['Class 0', 'Class 1'])\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the binary image classification process.\n",
    "    \"\"\"\n",
    "    print(\"Binary Image Classification using SIFT, BoVW, and ANN (MLPClassifier)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Get input folder paths\n",
    "    print(\"\\nPlease enter the paths to the image folders:\")\n",
    "    train_path_class1 = \"./resources/classification/cats\"\n",
    "    train_path_class2 = \"./resources/classification/dogs\"\n",
    "    test_path_class1 = \"./resources/classification/cat_test\"\n",
    "    test_path_class2 = \"./resources/classification/dog_test\"\n",
    "    \n",
    "    # Validate paths\n",
    "    for path in [train_path_class1, train_path_class2, test_path_class1, test_path_class2]:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Error: Path {path} does not exist!\")\n",
    "            return\n",
    "    \n",
    "    # Step 1: Extract SIFT descriptors from training images\n",
    "    print(\"\\nStep 1: Extracting SIFT descriptors from training images...\")\n",
    "    class1_descriptors, class1_img_descriptors, class1_labels = load_images_and_extract_sift(train_path_class1, 0)\n",
    "    class2_descriptors, class2_img_descriptors, class2_labels = load_images_and_extract_sift(train_path_class2, 1)\n",
    "    \n",
    "    # Combine descriptors from both classes\n",
    "    if len(class1_descriptors) > 0 and len(class2_descriptors) > 0:\n",
    "        all_train_descriptors = np.vstack([class1_descriptors, class2_descriptors])\n",
    "    elif len(class1_descriptors) > 0:\n",
    "        all_train_descriptors = class1_descriptors\n",
    "    elif len(class2_descriptors) > 0:\n",
    "        all_train_descriptors = class2_descriptors\n",
    "    else:\n",
    "        print(\"Error: No SIFT descriptors could be extracted from the training images!\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Determine optimal K using Elbow Method\n",
    "    print(\"\\nStep 2: Plotting Elbow Method to determine optimal K...\")\n",
    "    max_k = int(input(\"Enter maximum K to try for Elbow Method (recommend 20-50): \"))\n",
    "    plot_elbow_method(all_train_descriptors, max_k)\n",
    "    \n",
    "    # Get K from user\n",
    "    num_clusters = int(input(\"\\nBased on the Elbow Method plot, enter the optimal K value: \"))\n",
    "    \n",
    "    # Step 3: Build visual vocabulary (K-means clustering)\n",
    "    print(\"\\nStep 3: Building visual vocabulary...\")\n",
    "    kmeans_model = build_visual_vocabulary(all_train_descriptors, num_clusters)\n",
    "    \n",
    "    # Step 4: Create BoVW histograms for training images\n",
    "    print(\"\\nStep 4: Creating BoVW histograms for training images...\")\n",
    "    X_train_class1, y_train_class1 = process_image_folder_to_bovw(train_path_class1, 0, kmeans_model)\n",
    "    X_train_class2, y_train_class2 = process_image_folder_to_bovw(train_path_class2, 1, kmeans_model)\n",
    "    \n",
    "    # Combine training data\n",
    "    if len(X_train_class1) > 0 and len(X_train_class2) > 0:\n",
    "        X_train = np.vstack([X_train_class1, X_train_class2])\n",
    "        y_train = np.concatenate([y_train_class1, y_train_class2])\n",
    "    elif len(X_train_class1) > 0:\n",
    "        X_train = X_train_class1\n",
    "        y_train = y_train_class1\n",
    "    elif len(X_train_class2) > 0:\n",
    "        X_train = X_train_class2\n",
    "        y_train = y_train_class2\n",
    "    else:\n",
    "        print(\"Error: Could not create BoVW features for training images!\")\n",
    "        return\n",
    "    \n",
    "    # Step 5: Create BoVW histograms for test images\n",
    "    print(\"\\nStep 5: Creating BoVW histograms for test images...\")\n",
    "    X_test_class1, y_test_class1 = process_image_folder_to_bovw(test_path_class1, 0, kmeans_model)\n",
    "    X_test_class2, y_test_class2 = process_image_folder_to_bovw(test_path_class2, 1, kmeans_model)\n",
    "    \n",
    "    # Combine test data\n",
    "    if len(X_test_class1) > 0 and len(X_test_class2) > 0:\n",
    "        X_test = np.vstack([X_test_class1, X_test_class2])\n",
    "        y_test = np.concatenate([y_test_class1, y_test_class2])\n",
    "    elif len(X_test_class1) > 0:\n",
    "        X_test = X_test_class1\n",
    "        y_test = y_test_class1\n",
    "    elif len(X_test_class2) > 0:\n",
    "        X_test = X_test_class2\n",
    "        y_test = y_test_class2\n",
    "    else:\n",
    "        print(\"Error: Could not create BoVW features for test images!\")\n",
    "        return\n",
    "    \n",
    "    # Print data shape information\n",
    "    print(f\"\\nTraining data shape: {X_train.shape}, Labels shape: {y_train.shape}\")\n",
    "    print(f\"Testing data shape: {X_test.shape}, Labels shape: {y_test.shape}\")\n",
    "    \n",
    "    # Step 6: Get ANN parameters from user\n",
    "    print(\"\\nStep 6: Setting up ANN (MLPClassifier)...\")\n",
    "    print(\"\\nANN Model Hyperparameter Suggestions:\")\n",
    "    print(\"- hidden_layer_sizes: tuple of neurons per layer, e.g. (64, 32)\")\n",
    "    print(\"- activation: 'relu' (default), 'tanh', 'logistic'\")\n",
    "    print(\"- solver: 'adam' (default), 'sgd', 'lbfgs'\")\n",
    "    print(\"- alpha: L2 penalty (regularization), default 0.0001\")\n",
    "    print(\"- learning_rate_init: Learning rate, default 0.001\")\n",
    "    print(\"- max_iter: Maximum iterations, default 300\")\n",
    "    print(\"- batch_size: 'auto', or integer (8, 16, 32, etc.)\")\n",
    "    print(\"- early_stopping: True/False\")\n",
    "    \n",
    "    print(\"\\nEnter ANN hyperparameters (press Enter to use defaults):\")\n",
    "    \n",
    "    # Get hidden layer configuration\n",
    "    hidden_layers_input = input(\"Hidden layer sizes (comma-separated, e.g., '64,32'): \")\n",
    "    hidden_layers = (64, 32)  # Default\n",
    "    if hidden_layers_input.strip():\n",
    "        hidden_layers = tuple(int(x) for x in hidden_layers_input.split(','))\n",
    "    \n",
    "    # Get activation function\n",
    "    activation_input = input(\"Activation function ['relu', 'tanh', 'logistic']: \")\n",
    "    activation = 'relu'  # Default\n",
    "    if activation_input.strip():\n",
    "        activation = activation_input.strip()\n",
    "    \n",
    "    # Get solver\n",
    "    solver_input = input(\"Solver ['adam', 'sgd', 'lbfgs']: \")\n",
    "    solver = 'adam'  # Default\n",
    "    if solver_input.strip():\n",
    "        solver = solver_input.strip()\n",
    "    \n",
    "    # Get alpha (regularization)\n",
    "    alpha_input = input(\"Alpha (L2 penalty) [0.0001]: \")\n",
    "    alpha = 0.0001  # Default\n",
    "    if alpha_input.strip():\n",
    "        alpha = float(alpha_input)\n",
    "    \n",
    "    # Get max_iter\n",
    "    max_iter_input = input(\"Maximum iterations [300]: \")\n",
    "    max_iter = 300  # Default\n",
    "    if max_iter_input.strip():\n",
    "        max_iter = int(max_iter_input)\n",
    "    \n",
    "    # Get early_stopping\n",
    "    early_stopping_input = input(\"Early stopping (True/False) [True]: \")\n",
    "    early_stopping = True  # Default\n",
    "    if early_stopping_input.strip().lower() == 'false':\n",
    "        early_stopping = False\n",
    "    \n",
    "    # Collect parameters\n",
    "    mlp_params = {\n",
    "        'hidden_layer_sizes': hidden_layers,\n",
    "        'activation': activation,\n",
    "        'solver': solver,\n",
    "        'alpha': alpha,\n",
    "        'max_iter': max_iter,\n",
    "        'early_stopping': early_stopping,\n",
    "        'random_state': 42,\n",
    "        'validation_fraction': 0.1 if early_stopping else 0.0\n",
    "    }\n",
    "    \n",
    "    # Step 7: Create and train ANN model\n",
    "    print(\"\\nStep 7: Creating and training ANN model...\")\n",
    "    ann_model = create_and_train_ann_model(X_train, y_train, mlp_params)\n",
    "    \n",
    "    # Step 8: Evaluate the model\n",
    "    print(\"\\nStep 8: Evaluating the model...\")\n",
    "    # Make predictions\n",
    "    y_pred = ann_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    metrics = evaluate_model(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\nBinary Image Classification process completed!\")\n",
    "    print(f\"Final F1-Score: {metrics['f1']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56870be4",
   "metadata": {},
   "source": [
    "3. Image classification using ANN with HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ad3f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Binary Image Classification using HOG Features and ANN\n",
    "\n",
    "This program classifies images into two classes using:\n",
    "1. HOG (Histogram of Oriented Gradients) feature extraction\n",
    "2. ANN (Artificial Neural Network) classification with MLPClassifier\n",
    "\n",
    "The program loads images from specified directories, extracts HOG features,\n",
    "trains an ANN model, and evaluates its performance with metrics like F1-score.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# HOG Feature Extraction Functions\n",
    "def extract_hog_descriptor(image_path, target_size=(64, 128), orientations=9, \n",
    "                          pixels_per_cell=(8, 8), cells_per_block=(2, 2), \n",
    "                          block_norm='L2-Hys', visualize=False):\n",
    "    \"\"\"\n",
    "    Extract HOG descriptor from a single image.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        target_size (tuple): Size to resize the image to before HOG extraction\n",
    "        orientations (int): Number of orientation bins for HOG\n",
    "        pixels_per_cell (tuple): Size of a cell in pixels\n",
    "        cells_per_block (tuple): Number of cells in each block\n",
    "        block_norm (str): Block normalization method\n",
    "        visualize (bool): Whether to return the HOG visualization\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: HOG feature vector for the image\n",
    "        numpy.ndarray (optional): HOG visualization if visualize=True\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Resize image to target size\n",
    "        resized = cv2.resize(gray, target_size)\n",
    "        \n",
    "        # Extract HOG features\n",
    "        if visualize:\n",
    "            hog_features, hog_image = hog(\n",
    "                resized, \n",
    "                orientations=orientations,\n",
    "                pixels_per_cell=pixels_per_cell,\n",
    "                cells_per_block=cells_per_block,\n",
    "                block_norm=block_norm,\n",
    "                visualize=True\n",
    "            )\n",
    "            return hog_features, hog_image\n",
    "        else:\n",
    "            hog_features = hog(\n",
    "                resized, \n",
    "                orientations=orientations,\n",
    "                pixels_per_cell=pixels_per_cell,\n",
    "                cells_per_block=cells_per_block,\n",
    "                block_norm=block_norm,\n",
    "                visualize=False\n",
    "            )\n",
    "            return hog_features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_images_and_extract_hog(folder_path, label, hog_params):\n",
    "    \"\"\"\n",
    "    Extract HOG features from all images in a folder and create labels.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing images\n",
    "        label (int): Class label (0 or 1)\n",
    "        hog_params (dict): Parameters for HOG feature extraction\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (features, labels)\n",
    "            - features: List of HOG feature vectors for all images\n",
    "            - labels: List of labels corresponding to each image\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Get all image files in the folder\n",
    "    image_paths = []\n",
    "    for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
    "        image_paths.extend(glob.glob(os.path.join(folder_path, ext)))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"Warning: No images found in {folder_path}\")\n",
    "        return features, labels\n",
    "    \n",
    "    print(f\"Processing {len(image_paths)} images from {folder_path}...\")\n",
    "    \n",
    "    # Process each image\n",
    "    for img_path in image_paths:\n",
    "        # Extract HOG features\n",
    "        hog_features = extract_hog_descriptor(\n",
    "            img_path, \n",
    "            target_size=hog_params.get('target_size', (64, 128)),\n",
    "            orientations=hog_params.get('orientations', 9),\n",
    "            pixels_per_cell=hog_params.get('pixels_per_cell', (8, 8)),\n",
    "            cells_per_block=hog_params.get('cells_per_block', (2, 2)),\n",
    "            block_norm=hog_params.get('block_norm', 'L2-Hys')\n",
    "        )\n",
    "        \n",
    "        if hog_features is not None:\n",
    "            features.append(hog_features)\n",
    "            labels.append(label)\n",
    "    \n",
    "    print(f\"Extracted HOG features from {len(features)} images\")\n",
    "    return features, labels\n",
    "\n",
    "def visualize_hog_features(image_path, hog_params):\n",
    "    \"\"\"\n",
    "    Visualize HOG features for a sample image.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        hog_params (dict): Parameters for HOG feature extraction\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract HOG features with visualization\n",
    "        hog_features, hog_image = extract_hog_descriptor(\n",
    "            image_path, \n",
    "            target_size=hog_params.get('target_size', (64, 128)),\n",
    "            orientations=hog_params.get('orientations', 9),\n",
    "            pixels_per_cell=hog_params.get('pixels_per_cell', (8, 8)),\n",
    "            cells_per_block=hog_params.get('cells_per_block', (2, 2)),\n",
    "            block_norm=hog_params.get('block_norm', 'L2-Hys'),\n",
    "            visualize=True\n",
    "        )\n",
    "        \n",
    "        # Read and resize original image for visualization\n",
    "        img = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, hog_params.get('target_size', (64, 128)))\n",
    "        \n",
    "        # Display original and HOG images\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(resized, cmap='gray')\n",
    "        ax1.set_title('Original Image (Grayscale)')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        ax2.imshow(hog_image, cmap='gray')\n",
    "        ax2.set_title('HOG Visualization')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"HOG Feature vector shape: {hog_features.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing HOG features: {str(e)}\")\n",
    "\n",
    "# ANN Model Functions\n",
    "def create_and_train_ann_model(X_train, y_train, mlp_params=None):\n",
    "    \"\"\"\n",
    "    Create and train an Artificial Neural Network model using MLPClassifier.\n",
    "    \n",
    "    Args:\n",
    "        X_train (numpy.ndarray): Training features (HOG features)\n",
    "        y_train (numpy.ndarray): Training labels\n",
    "        mlp_params (dict): Parameters for MLPClassifier\n",
    "        \n",
    "    Returns:\n",
    "        MLPClassifier: Trained ANN model\n",
    "    \"\"\"\n",
    "    # Set default parameters if none provided\n",
    "    if mlp_params is None:\n",
    "        mlp_params = {\n",
    "            'hidden_layer_sizes': (100,),\n",
    "            'activation': 'relu',\n",
    "            'solver': 'adam',\n",
    "            'alpha': 0.0001,\n",
    "            'max_iter': 300,\n",
    "            'batch_size': 'auto',\n",
    "            'learning_rate_init': 0.001,\n",
    "            'early_stopping': True,\n",
    "            'validation_fraction': 0.1,\n",
    "            'random_state': 42\n",
    "        }\n",
    "    \n",
    "    print(\"Creating and training MLPClassifier...\")\n",
    "    print(f\"Parameters: {mlp_params}\")\n",
    "    \n",
    "    # Create MLP model\n",
    "    model = MLPClassifier(**mlp_params)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"MLPClassifier trained successfully\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate the model performance.\n",
    "    \n",
    "    Args:\n",
    "        y_true (numpy.ndarray): Ground truth labels\n",
    "        y_pred (numpy.ndarray): Predicted labels\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    # Print evaluation results\n",
    "    print(\"\\nModel Evaluation Results:\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, ['Class 0', 'Class 1'], rotation=45)\n",
    "    plt.yticks(tick_marks, ['Class 0', 'Class 1'])\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the binary image classification process.\n",
    "    \"\"\"\n",
    "    print(\"Binary Image Classification using HOG Features and ANN (MLPClassifier)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Get input folder paths\n",
    "    print(\"\\nPlease enter the paths to the image folders:\")\n",
    "    train_path_class1 = \"./resources/classification/cats\"\n",
    "    train_path_class2 = \"./resources/classification/dogs\"\n",
    "    test_path_class1 = \"./resources/classification/cat_test\"\n",
    "    test_path_class2 = \"./resources/classification/dog_test\"\n",
    "    \n",
    "    # Validate paths\n",
    "    for path in [train_path_class1, train_path_class2, test_path_class1, test_path_class2]:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Error: Path {path} does not exist!\")\n",
    "            return\n",
    "    \n",
    "    # Step 1: Configure HOG parameters\n",
    "    print(\"\\nStep 1: Configure HOG parameters (press Enter to use defaults)\")\n",
    "    print(\"\\nHOG Parameter Suggestions:\")\n",
    "    print(\"- target_size: Image size for HOG extraction, e.g., (64, 128) or (128, 128)\")\n",
    "    print(\"- orientations: Number of orientation bins (typically 9)\")\n",
    "    print(\"- pixels_per_cell: Cell size in pixels, e.g., (8, 8)\")\n",
    "    print(\"- cells_per_block: Number of cells per block, e.g., (2, 2)\")\n",
    "    print(\"- block_norm: Block normalization method, e.g., 'L2-Hys'\")\n",
    "    \n",
    "    # Get target_size\n",
    "    target_width = input(\"Target width [64]: \")\n",
    "    target_height = input(\"Target height [128]: \")\n",
    "    target_size = (\n",
    "        int(target_width) if target_width.strip() else 64,\n",
    "        int(target_height) if target_height.strip() else 128\n",
    "    )\n",
    "    \n",
    "    # Get orientations\n",
    "    orientations_input = input(\"Orientations [9]: \")\n",
    "    orientations = int(orientations_input) if orientations_input.strip() else 9\n",
    "    \n",
    "    # Get pixels_per_cell\n",
    "    ppc_x = input(\"Pixels per cell (width) [8]: \")\n",
    "    ppc_y = input(\"Pixels per cell (height) [8]: \")\n",
    "    pixels_per_cell = (\n",
    "        int(ppc_x) if ppc_x.strip() else 8,\n",
    "        int(ppc_y) if ppc_y.strip() else 8\n",
    "    )\n",
    "    \n",
    "    # Get cells_per_block\n",
    "    cpb_x = input(\"Cells per block (width) [2]: \")\n",
    "    cpb_y = input(\"Cells per block (height) [2]: \")\n",
    "    cells_per_block = (\n",
    "        int(cpb_x) if cpb_x.strip() else 2,\n",
    "        int(cpb_y) if cpb_y.strip() else 2\n",
    "    )\n",
    "    \n",
    "    # Get block_norm\n",
    "    block_norm_input = input(\"Block normalization method ['L2-Hys']: \")\n",
    "    block_norm = block_norm_input if block_norm_input.strip() else 'L2-Hys'\n",
    "    \n",
    "    # Collect HOG parameters\n",
    "    hog_params = {\n",
    "        'target_size': target_size,\n",
    "        'orientations': orientations,\n",
    "        'pixels_per_cell': pixels_per_cell,\n",
    "        'cells_per_block': cells_per_block,\n",
    "        'block_norm': block_norm\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nHOG Parameters: {hog_params}\")\n",
    "    \n",
    "    # Step 2: Visualize HOG features for a sample image (optional)\n",
    "    visualize_option = input(\"\\nDo you want to visualize HOG features for a sample image? (y/n): \")\n",
    "    if visualize_option.lower() == 'y':\n",
    "        sample_path = input(\"Enter the path to a sample image: \")\n",
    "        if os.path.exists(sample_path):\n",
    "            visualize_hog_features(sample_path, hog_params)\n",
    "        else:\n",
    "            print(f\"Error: Sample image path {sample_path} does not exist\")\n",
    "    \n",
    "    # Step 3: Extract HOG features from training images\n",
    "    print(\"\\nStep 3: Extracting HOG features from training images...\")\n",
    "    X_train_class1, y_train_class1 = load_images_and_extract_hog(train_path_class1, 0, hog_params)\n",
    "    X_train_class2, y_train_class2 = load_images_and_extract_hog(train_path_class2, 1, hog_params)\n",
    "    \n",
    "    # Combine training data\n",
    "    if X_train_class1 and X_train_class2:\n",
    "        X_train = np.vstack([X_train_class1, X_train_class2])\n",
    "        y_train = np.array(y_train_class1 + y_train_class2)\n",
    "    else:\n",
    "        print(\"Error: Could not extract HOG features from training images\")\n",
    "        return\n",
    "    \n",
    "    # Step 4: Extract HOG features from test images\n",
    "    print(\"\\nStep 4: Extracting HOG features from test images...\")\n",
    "    X_test_class1, y_test_class1 = load_images_and_extract_hog(test_path_class1, 0, hog_params)\n",
    "    X_test_class2, y_test_class2 = load_images_and_extract_hog(test_path_class2, 1, hog_params)\n",
    "    \n",
    "    # Combine test data\n",
    "    if X_test_class1 and X_test_class2:\n",
    "        X_test = np.vstack([X_test_class1, X_test_class2])\n",
    "        y_test = np.array(y_test_class1 + y_test_class2)\n",
    "    else:\n",
    "        print(\"Error: Could not extract HOG features from test images\")\n",
    "        return\n",
    "    \n",
    "    # Print data shape information\n",
    "    print(f\"\\nTraining data shape: {X_train.shape}, Labels shape: {y_train.shape}\")\n",
    "    print(f\"Testing data shape: {X_test.shape}, Labels shape: {y_test.shape}\")\n",
    "    \n",
    "    # Step 5: Normalize features using StandardScaler\n",
    "    print(\"\\nStep 5: Normalizing features using StandardScaler...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print(\"Feature normalization completed\")\n",
    "    \n",
    "    # Step 6: Configure ANN parameters\n",
    "    print(\"\\nStep 6: Configure ANN parameters (press Enter to use defaults)\")\n",
    "    print(\"\\nANN Parameter Suggestions:\")\n",
    "    print(\"- hidden_layer_sizes: Tuple of neurons per layer, e.g., (100,) or (64, 32)\")\n",
    "    print(\"- activation: 'relu' (default), 'tanh', 'logistic'\")\n",
    "    print(\"- solver: 'adam' (default), 'sgd', 'lbfgs'\")\n",
    "    print(\"- alpha: L2 penalty (regularization), default 0.0001\")\n",
    "    print(\"- learning_rate_init: Learning rate, default 0.001\")\n",
    "    print(\"- max_iter: Maximum iterations, default 300\")\n",
    "    print(\"- batch_size: 'auto', or integer (8, 16, 32, etc.)\")\n",
    "    print(\"- early_stopping: True/False\")\n",
    "    \n",
    "    # Get hidden layer configuration\n",
    "    hidden_layers_input = input(\"Hidden layer sizes (comma-separated, e.g., '100' or '64,32'): \")\n",
    "    hidden_layers = (100,)  # Default\n",
    "    if hidden_layers_input.strip():\n",
    "        hidden_layers = tuple(int(x) for x in hidden_layers_input.split(','))\n",
    "    \n",
    "    # Get activation function\n",
    "    activation_input = input(\"Activation function ['relu', 'tanh', 'logistic']: \")\n",
    "    activation = 'relu'  # Default\n",
    "    if activation_input.strip():\n",
    "        activation = activation_input.strip()\n",
    "    \n",
    "    # Get solver\n",
    "    solver_input = input(\"Solver ['adam', 'sgd', 'lbfgs']: \")\n",
    "    solver = 'adam'  # Default\n",
    "    if solver_input.strip():\n",
    "        solver = solver_input.strip()\n",
    "    \n",
    "    # Get alpha (regularization)\n",
    "    alpha_input = input(\"Alpha (L2 penalty) [0.0001]: \")\n",
    "    alpha = 0.0001  # Default\n",
    "    if alpha_input.strip():\n",
    "        alpha = float(alpha_input)\n",
    "    \n",
    "    # Get learning_rate_init\n",
    "    lr_input = input(\"Learning rate [0.001]: \")\n",
    "    learning_rate_init = 0.001  # Default\n",
    "    if lr_input.strip():\n",
    "        learning_rate_init = float(lr_input)\n",
    "    \n",
    "    # Get max_iter\n",
    "    max_iter_input = input(\"Maximum iterations [300]: \")\n",
    "    max_iter = 300  # Default\n",
    "    if max_iter_input.strip():\n",
    "        max_iter = int(max_iter_input)\n",
    "    \n",
    "    # Get early_stopping\n",
    "    early_stopping_input = input(\"Early stopping (True/False) [True]: \")\n",
    "    early_stopping = True  # Default\n",
    "    if early_stopping_input.strip().lower() == 'false':\n",
    "        early_stopping = False\n",
    "    \n",
    "    # Collect ANN parameters\n",
    "    mlp_params = {\n",
    "        'hidden_layer_sizes': hidden_layers,\n",
    "        'activation': activation,\n",
    "        'solver': solver,\n",
    "        'alpha': alpha,\n",
    "        'learning_rate_init': learning_rate_init,\n",
    "        'max_iter': max_iter,\n",
    "        'early_stopping': early_stopping,\n",
    "        'random_state': 42,\n",
    "        'validation_fraction': 0.1 if early_stopping else 0.0\n",
    "    }\n",
    "    \n",
    "    # Step 7: Create and train ANN model\n",
    "    print(\"\\nStep 7: Creating and training ANN model...\")\n",
    "    ann_model = create_and_train_ann_model(X_train_scaled, y_train, mlp_params)\n",
    "    \n",
    "    # Step 8: Evaluate the model\n",
    "    print(\"\\nStep 8: Evaluating the model...\")\n",
    "    \n",
    "    # Train set evaluation (optional)\n",
    "    evaluate_train = input(\"Do you want to evaluate on the training set? (y/n): \")\n",
    "    if evaluate_train.lower() == 'y':\n",
    "        print(\"\\nTraining Set Evaluation:\")\n",
    "        y_train_pred = ann_model.predict(X_train_scaled)\n",
    "        _ = evaluate_model(y_train, y_train_pred)\n",
    "    \n",
    "    # Test set evaluation\n",
    "    print(\"\\nTest Set Evaluation:\")\n",
    "    y_test_pred = ann_model.predict(X_test_scaled)\n",
    "    metrics = evaluate_model(y_test, y_test_pred)\n",
    "    \n",
    "    print(\"\\nBinary Image Classification process completed!\")\n",
    "    print(f\"Final F1-Score: {metrics['f1']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fbe1d6",
   "metadata": {},
   "source": [
    "2. Pedestrian Detection using CV2 built-in function (0.5)\n",
    "\n",
    "- Input: images/clip containing pedestrians (video (2160).mp4 / people.mp4 or your videos)\n",
    "\n",
    "- Output: images with green boxes rounding pedestrians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b82743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import imutils\n",
    "\n",
    "def detect_pedestrians(file_path, option='image'):\n",
    "\n",
    "    # Initialize HOG descriptor and set default pedestrian detector\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "    if option == 'image':\n",
    "        # Reading the Image\n",
    "        image = cv2.imread(file_path)\n",
    "        if image is None:\n",
    "            print(f\"Error: Could not read image from {file_path}\")\n",
    "            return\n",
    "\n",
    "        # Resizing the Image\n",
    "        image = imutils.resize(image, width=min(400, image.shape[1]))\n",
    "\n",
    "        # Detect pedestrians\n",
    "        print(\"Detecting pedestrians in image...\")\n",
    "        (rects, weights) = hog.detectMultiScale(image, winStride=(4, 4), \n",
    "                                               padding=(4, 4), scale=1.05)\n",
    "        print(f\"Found {len(rects)} pedestrians\")\n",
    "\n",
    "        # Draw bounding boxes around detected pedestrians\n",
    "        for (x, y, w, h) in rects:\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Green boxes\n",
    "\n",
    "        # Convert BGR to RGB for matplotlib display\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display the result\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(image_rgb)\n",
    "        plt.title(f'Detected {len(rects)} pedestrians')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    elif option == 'video':\n",
    "        # Open the video file\n",
    "        video = cv2.VideoCapture(file_path)\n",
    "        if not video.isOpened():\n",
    "            print(f\"Error: Could not open video from {file_path}\")\n",
    "            return\n",
    "        \n",
    "        # Get video frame width, height, and FPS for VideoWriter\n",
    "        frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        frame_count = 0\n",
    "        \n",
    "        # Define codec and create VideoWriter object\n",
    "        output_path = 'output_video.avi'\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (640, 480))\n",
    "        \n",
    "        \n",
    "        print(\"Processing video frames...\")\n",
    "        while True:\n",
    "            ret, frame = video.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "            # Detect pedestrians\n",
    "            boxes, _ = hog.detectMultiScale(frame, winStride=(8, 8), padding=(8, 8), scale=1.2)\n",
    "\n",
    "            # Draw green rectangles\n",
    "            for (x, y, w, h) in boxes:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "            # Write frame to output video\n",
    "            out.write(frame)\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Display progress\n",
    "            if frame_count % 30 == 0:\n",
    "                print(f\"Processed {frame_count} frames...\")\n",
    "        \n",
    "        # Release resources\n",
    "        video.release()\n",
    "        out.release()\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"Video processing completed.\")\n",
    "        print(f\"Total frames processed: {frame_count}\")\n",
    "        print(f\"Output saved to: {output_path}\")\n",
    "            \n",
    "    else:\n",
    "        print(\"Invalid option. Use 'image' or 'video'\")\n",
    "\n",
    "# Example usage:\n",
    "# detect_pedestrians('./resources/img.jpg', 'image')\n",
    "detect_pedestrians('./resources/video_1.mp4', 'video')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a9bb9",
   "metadata": {},
   "source": [
    "Hello word\n",
    "(1) vit nam\n",
    "(2) vit nam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
