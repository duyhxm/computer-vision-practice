{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b38b618",
   "metadata": {},
   "source": [
    "### 1 Face/Full Body Detection (0.5) using Cascade Classifier (0.5)\n",
    "\n",
    "Input: camera capture or MP4\n",
    "\n",
    "Output: MP4 with green boxes rounding Face(s)/Full Body(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a6302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def main():\n",
    "    # Get input source\n",
    "    input_source = \"\"\n",
    "    while input_source not in [\"cam\", \"mp4\"]:\n",
    "        input_source = input(\"Enter input source ('cam' for camera, 'mp4' for video file): \").lower()\n",
    "    \n",
    "    # Get video file path if MP4 is selected\n",
    "    video_path = \"./resources/video_detection_1.mp4\"\n",
    "    \n",
    "    #Determine detection type\n",
    "    detection_type = \"\"\n",
    "    while detection_type not in [\"face\", \"body\", \"eye\" , \"all\"]:\n",
    "        detection_type = input(\"Enter detection type ('face', 'body', 'eye' or 'all'): \").lower()\n",
    "    \n",
    "    # Get output file path if MP4 is selected as input\n",
    "    output_path = None\n",
    "    if input_source == \"mp4\":\n",
    "        output_path = input(\"Enter output MP4 file path: \")\n",
    "        if not output_path.endswith('.mp4'):\n",
    "            output_path += '.mp4'\n",
    "    \n",
    "    # Initialize cascade classifiers\n",
    "    face_cascade = None\n",
    "    # body_cascade = None\n",
    "    eye_cascade = None\n",
    "    \n",
    "    # Load face cascade if needed\n",
    "    if detection_type in [\"face\", \"all\"]:\n",
    "        # Find the cascade file in OpenCV's data directory\n",
    "        face_cascade_path = os.path.join(cv2.data.haarcascades, 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "        if not os.path.exists(face_cascade_path):\n",
    "            print(f\"Error: Face cascade file not found at {face_cascade_path}\")\n",
    "            return\n",
    "        \n",
    "        face_cascade = cv2.CascadeClassifier(face_cascade_path)\n",
    "        # Check if cascade loaded successfully\n",
    "        if face_cascade.empty():\n",
    "            print(\"Error: Failed to load face cascade classifier\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"Face cascade loaded successfully from {face_cascade_path}\")\n",
    "    \n",
    "    if detection_type in [\"eye\", \"all\"]:\n",
    "       \n",
    "        eye_cascade_path = \"./resources/haarcascade_eye.xml\"\n",
    "        if not os.path.exists(eye_cascade_path):\n",
    "            print(f\"Error: Eye cascade file not found at {eye_cascade_path}\")\n",
    "            return\n",
    "        \n",
    "        eye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n",
    "        # Check if cascade loaded successfully\n",
    "        if eye_cascade.empty():\n",
    "            print(\"Error: Failed to load eye cascade classifier\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"Eye cascade loaded successfully from {eye_cascade_path}\")\n",
    "    \n",
    "    # Load body cascade if needed\n",
    "    # if detection_type in [\"body\", \"all\"]:\n",
    "    #     # Find the cascade file in OpenCV's data directory\n",
    "    #     body_cascade_path = os.path.join(cv2.data.haarcascades, 'haarcascade_fullbody.xml')\n",
    "    #     if not os.path.exists(body_cascade_path):\n",
    "    #         print(f\"Error: Body cascade file not found at {body_cascade_path}\")\n",
    "    #         return\n",
    "        \n",
    "    #     body_cascade = cv2.CascadeClassifier(body_cascade_path)\n",
    "    #     # Check if cascade loaded successfully\n",
    "    #     if body_cascade.empty():\n",
    "    #         print(\"Error: Failed to load body cascade classifier\")\n",
    "    #         return\n",
    "    #     else:\n",
    "    #         print(f\"Body cascade loaded successfully from {body_cascade_path}\")\n",
    "    \n",
    "    # Initialize video capture\n",
    "    if input_source == \"cam\":\n",
    "        video_capture = cv2.VideoCapture(0)  # Use default camera (webcam)\n",
    "    else:\n",
    "        video_capture = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not video_capture.isOpened():\n",
    "        print(\"Error: Could not open video source\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "    if fps == 0: #If cannot get actual fps\n",
    "        fps = 30  # Default to 30 fps\n",
    "    \n",
    "    # Initialize video writer if needed\n",
    "    video_writer = None\n",
    "    if input_source == \"mp4\":\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
    "        video_writer = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Process video frames\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        if not ret:\n",
    "            # End of video or error\n",
    "            break\n",
    "        \n",
    "        # Convert frame to grayscale for detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces if needed\n",
    "        if detection_type in [\"face\", \"all\"] and face_cascade_path is not None:\n",
    "            faces = face_cascade.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor=1.1,  # How much the image size is reduced at each image scale\n",
    "                minNeighbors=5,   # How many neighbors each candidate rectangle should have\n",
    "                minSize=(30, 30)  # Minimum possible object size\n",
    "            )\n",
    "            \n",
    "            # Draw rectangles around faces\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)  # Green color, thickness 2\n",
    "\n",
    "        # Detect eyes if needed (standalone, not within faces)\n",
    "        if detection_type in [\"eye\", \"all\"] and eye_cascade is not None:\n",
    "            eyes = eye_cascade.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor=1.05,\n",
    "                minNeighbors=5,\n",
    "                minSize=(10, 10)\n",
    "            )\n",
    "            \n",
    "            # Draw rectangles around eyes\n",
    "            for (x, y, w, h) in eyes:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        # Detect bodies if needed\n",
    "        # if detection_type in [\"body\", \"all\"]:\n",
    "        #     bodies = body_cascade.detectMultiScale(\n",
    "        #         gray,\n",
    "        #         scaleFactor=1.2,  # Lower scale factor for better detection\n",
    "        #         minNeighbors=3,    # Fewer neighbors to detect more bodies\n",
    "        #         minSize=(30, 60),  # Minimum size for a body rectangle\n",
    "        #         flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        #     )\n",
    "            \n",
    "        #     # Draw rectangles around bodies\n",
    "        #     for (x, y, w, h) in bodies:\n",
    "        #         cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)  # Red color, thickness 2\n",
    "        \n",
    "        # Display or write the frame\n",
    "        if input_source == \"cam\":\n",
    "            cv2.imshow('Detection', frame)\n",
    "            \n",
    "            # Break loop on 'q' key press\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            video_writer.write(frame)\n",
    "            \n",
    "            # Optional: show progress\n",
    "            if int(video_capture.get(cv2.CAP_PROP_POS_FRAMES)) % 30 == 0:\n",
    "                print(f\"Processing: {int(video_capture.get(cv2.CAP_PROP_POS_FRAMES))} frames done\")\n",
    "    \n",
    "    # Release resources\n",
    "    video_capture.release()\n",
    "    if video_writer:\n",
    "        video_writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    if input_source == \"mp4\":\n",
    "        print(f\"Output video saved to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ce2b8",
   "metadata": {},
   "source": [
    "### 2 Image Retrieval using SIFT features\n",
    "\n",
    "Input: query image\n",
    "\n",
    "Output: Top k  (default = 5) similarity images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Path to the query image (the image you want to find similar images to)\n",
    "QUERY_IMAGE_PATH = r\"./resources/query-image.jpg\"\n",
    "\n",
    "# Path to the folder containing database images (can contain subfolders)\n",
    "DATABASE_FOLDER_PATH = r\"./resources/classification\"\n",
    "\n",
    "# Path where the results will be saved\n",
    "OUTPUT_FILE_PATH = r\"output.txt\"\n",
    "\n",
    "# Number of most similar images to return\n",
    "K_RESULTS = 5\n",
    "\n",
    "COSINE_SIMILARITY_THRESHOLD = 0.8\n",
    "\n",
    "#Computing SIFT features\n",
    "def extract_sift_features(image_path):\n",
    "    \"\"\"Extract SIFT features from an image.\"\"\"\n",
    "    try:\n",
    "        # Read the image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Error: Could not read image at {image_path}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Initialize SIFT detector\n",
    "        sift = cv2.SIFT_create(nfeatures = 100)\n",
    "        \n",
    "        # Detect keypoints and compute descriptors\n",
    "        keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "        \n",
    "        return keypoints, descriptors\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "def get_all_image_paths(database_folder):\n",
    "    \"\"\"Get paths of all images in the database folder and its subfolders.\"\"\"\n",
    "    image_paths = []\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
    "    \n",
    "    # Walk through all directories and subdirectories\n",
    "    for root, _, files in os.walk(database_folder):\n",
    "        for file in files:\n",
    "            # Check if the file is an image\n",
    "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "def match_features(query_descriptors, db_descriptors):\n",
    "    \"\"\"Match features between query and database image using cosine similarity.\"\"\"\n",
    "    # No descriptors to match\n",
    "    if query_descriptors is None or db_descriptors is None or len(query_descriptors) == 0 or len(db_descriptors) == 0:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Ensure descriptors are float32 for cosine_similarity\n",
    "        query_descriptors = query_descriptors.astype(np.float32)\n",
    "        db_descriptors = db_descriptors.astype(np.float32)\n",
    "\n",
    "         # Normalize query descriptors using StandardScaler\n",
    "        query_scaler = StandardScaler()\n",
    "        query_descriptors_norm = query_scaler.fit_transform(query_descriptors)\n",
    "        \n",
    "        # Normalize database descriptors using StandardScaler\n",
    "        db_scaler = StandardScaler()\n",
    "        db_descriptors_norm = db_scaler.fit_transform(db_descriptors)\n",
    "        \n",
    "        # Calculate cosine similarity using normalized descriptors\n",
    "        sim_matrix = cosine_similarity(query_descriptors_norm, db_descriptors_norm)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating cosine similarity: {e}\")\n",
    "        return []\n",
    "\n",
    "    good_matches = []\n",
    "    # For each query descriptor, find the best match in the database descriptors\n",
    "    for i in range(sim_matrix.shape[0]):\n",
    "        # Find the index and value of the highest similarity for query descriptor i\n",
    "        best_match_idx = np.argmax(sim_matrix[i])\n",
    "        best_match_score = sim_matrix[i, best_match_idx]\n",
    "\n",
    "        # If the best match similarity is above the threshold, consider it a good match\n",
    "        if best_match_score >= COSINE_SIMILARITY_THRESHOLD:\n",
    "            # Create a DMatch object. Distance is often defined as 1 - similarity\n",
    "            match = cv2.DMatch(_queryIdx=i, _trainIdx=best_match_idx, _distance=1.0 - best_match_score)\n",
    "            good_matches.append(match)\n",
    "\n",
    "    return good_matches\n",
    "\n",
    "def retrieve_similar_images(query_image_path, database_folder, k=2):\n",
    "    \"\"\"Find the k most similar images to the query image in the database.\"\"\"\n",
    "    # Check if query image exists\n",
    "    if not os.path.exists(query_image_path):\n",
    "        print(f\"Error: Query image not found at {query_image_path}\")\n",
    "        return []\n",
    "    \n",
    "    # Check if database folder exists\n",
    "    if not os.path.isdir(database_folder):\n",
    "        print(f\"Error: Database folder not found at {database_folder}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Extracting features from query image: {query_image_path}\")\n",
    "    \n",
    "    # Extract features from query image\n",
    "    query_keypoints, query_descriptors = extract_sift_features(query_image_path)\n",
    "    if query_descriptors is None:\n",
    "        print(\"Error: Could not extract features from query image\")\n",
    "        return []\n",
    "    \n",
    "    # Get all image paths from database\n",
    "    print(f\"Scanning database folder: {database_folder}\")\n",
    "    db_image_paths = get_all_image_paths(database_folder)\n",
    "    print(f\"Found {len(db_image_paths)} images in database\")\n",
    "    \n",
    "    # Initialize list to store similarity scores\n",
    "    similarity_scores = []\n",
    "    \n",
    "    # Process each database image\n",
    "    for i, db_image_path in enumerate(db_image_paths):\n",
    "        if i % 10 == 0:  # Progress update every 10 images\n",
    "            print(f\"Processing image {i+1}/{len(db_image_paths)}: {db_image_path}\")\n",
    "        \n",
    "        # Extract features from database image\n",
    "        db_keypoints, db_descriptors = extract_sift_features(db_image_path)\n",
    "        if db_descriptors is None:\n",
    "            continue\n",
    "        \n",
    "        # Match features\n",
    "        matches = match_features(query_descriptors, db_descriptors)\n",
    "        \n",
    "        # Store similarity score and image path\n",
    "        similarity_scores.append({\n",
    "            'path': db_image_path,\n",
    "            'matches': len(matches),\n",
    "            'filename': os.path.basename(db_image_path)\n",
    "        })\n",
    "    \n",
    "    # Sort by number of matches (descending)\n",
    "    similarity_scores.sort(key=lambda x: x['matches'], reverse=True)\n",
    "    \n",
    "    # Return top k results\n",
    "    return similarity_scores[:k]\n",
    "\n",
    "def save_results(results, output_path):\n",
    "    \"\"\"Save the retrieval results to a text file.\"\"\"\n",
    "    try:\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(f\"Top {len(results)} similar images:\\n\")\n",
    "            for i, result in enumerate(results):\n",
    "                f.write(f\"{i+1}. {result['filename']} - {result['matches']} matches - {result['path']}\\n\")\n",
    "        print(f\"Results saved to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the image retrieval process.\"\"\"\n",
    "    print(\"Image Retrieval using SIFT features\")\n",
    "    print(\"-----------------------------------\")\n",
    "    print(f\"Query image: {QUERY_IMAGE_PATH}\")\n",
    "    print(f\"Database folder: {DATABASE_FOLDER_PATH}\")\n",
    "    print(f\"Number of results (k): {K_RESULTS}\")\n",
    "    print(f\"Cosine Similarity Threshold: {COSINE_SIMILARITY_THRESHOLD}\")\n",
    "    print(\"-----------------------------------\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Retrieve similar images\n",
    "    results = retrieve_similar_images(\n",
    "        query_image_path=QUERY_IMAGE_PATH,\n",
    "        database_folder=DATABASE_FOLDER_PATH,\n",
    "        k=K_RESULTS\n",
    "    )\n",
    "    \n",
    "    if results:\n",
    "        # Save results to file\n",
    "        save_results(results, OUTPUT_FILE_PATH)\n",
    "        \n",
    "        # Print results to console\n",
    "        print(\"\\nTop matches:\")\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"{i+1}. {result['filename']} - {result['matches']} matches\")\n",
    "    else:\n",
    "        print(\"No results found or an error occurred during retrieval.\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nTotal processing time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
