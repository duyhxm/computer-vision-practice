{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1: Write a program to create a panorama image step-by-step\n",
    "\n",
    "The process is: SIFT points $\\rightarrow$ FLANN matcher $\\rightarrow$ RANSAC $\\rightarrow$ H matrix $\\rightarrow$ wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_images(image_paths):\n",
    "    \"\"\"\n",
    "    Load images from the provided file paths\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Warning: Image file {path} does not exist.\")\n",
    "            continue\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not load image {path}.\")\n",
    "            continue\n",
    "        images.append(img)\n",
    "    \n",
    "    return images\n",
    "\n",
    "def detect_and_match_features(img1, img2):\n",
    "    \"\"\"\n",
    "    Detect SIFT features and match them between two images using FLANN\n",
    "    \"\"\"\n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    # Find keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "    \n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    \n",
    "    # FLANN matcher\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    # Find the 2 nearest neighbors for each descriptor\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    # Apply Lowe's ratio test to filter good matches\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.7 * n.distance:  # Lowe's ratio test\n",
    "            good_matches.append(m)\n",
    "    \n",
    "    return kp1, kp2, good_matches\n",
    "\n",
    "def estimate_homography(kp1, kp2, good_matches, min_match_count=4):\n",
    "    \"\"\"\n",
    "    Estimate homography matrix using RANSAC\n",
    "    \"\"\"\n",
    "    if len(good_matches) < min_match_count:\n",
    "        print(f\"Not enough matches found: {len(good_matches)} < {min_match_count}\")\n",
    "        return None\n",
    "    \n",
    "    # Extract locations of matched keypoints\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # Find homography matrix using RANSAC\n",
    "    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    \n",
    "    # Count inliers (points that fit the homography model)\n",
    "    inliers = np.sum(mask)\n",
    "    print(f\"Homography estimation - Inliers: {inliers}/{len(good_matches)}\")\n",
    "    \n",
    "    return H\n",
    "\n",
    "def warp_and_stitch(img1, img2, H):\n",
    "    \"\"\"\n",
    "    Warp img1 using homography H and stitch with img2\n",
    "    \"\"\"\n",
    "    # Get dimensions\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "    \n",
    "    # Calculate the dimensions of the canvas based on the homography\n",
    "    corners1 = np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1, 1, 2)\n",
    "    corners2_transformed = cv2.perspectiveTransform(corners1, H)\n",
    "    \n",
    "    [xmin, ymin] = np.int32(corners2_transformed.min(axis=0).ravel() - 0.5)\n",
    "    [xmax, ymax] = np.int32(corners2_transformed.max(axis=0).ravel() + 0.5)\n",
    "    \n",
    "    # Offset to ensure all points are positive\n",
    "    t_x = -min(0, xmin)\n",
    "    t_y = -min(0, ymin)\n",
    "    \n",
    "    # Translation matrix\n",
    "    translation_matrix = np.array([\n",
    "        [1, 0, t_x],\n",
    "        [0, 1, t_y],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # Apply translation to the homography matrix\n",
    "    H_translation = translation_matrix.dot(H)\n",
    "    \n",
    "    # Determine canvas size\n",
    "    output_size = (max(xmax + t_x, w2 + t_x), max(ymax + t_y, h2 + t_y))\n",
    "    \n",
    "    # Warp the first image (img1) onto the canvas\n",
    "    warped_img = cv2.warpPerspective(img1, H_translation, output_size)\n",
    "    \n",
    "    # Create a new canvas for the second image\n",
    "    img2_canvas = np.zeros_like(warped_img)\n",
    "    img2_canvas[t_y:t_y+h2, t_x:t_x+w2] = img2\n",
    "    \n",
    "    # Create masks for non-black pixels in each image\n",
    "    warped_mask = (cv2.cvtColor(warped_img, cv2.COLOR_BGR2GRAY) > 0)\n",
    "    img2_mask = (cv2.cvtColor(img2_canvas, cv2.COLOR_BGR2GRAY) > 0)\n",
    "    \n",
    "    # Find overlapping regions\n",
    "    overlap = warped_mask & img2_mask\n",
    "    \n",
    "    # Apply simple blending\n",
    "    result = warped_img.copy()\n",
    "    \n",
    "    # In non-overlapping regions, keep the original pixels\n",
    "    # In overlapping regions, take the average of both images\n",
    "    for y in range(output_size[1]):\n",
    "        for x in range(output_size[0]):\n",
    "            if overlap[y, x]:\n",
    "                # Average the pixels in overlapping regions\n",
    "                result[y, x] = (warped_img[y, x].astype(np.float32) + \n",
    "                              img2_canvas[y, x].astype(np.float32)) / 2\n",
    "            elif img2_mask[y, x]:\n",
    "                # Use img2's pixel where there's no content in warped_img\n",
    "                result[y, x] = img2_canvas[y, x]\n",
    "    \n",
    "    return result.astype(np.uint8)\n",
    "\n",
    "\n",
    "def crop_black_borders(img):\n",
    "    \"\"\"\n",
    "    Advanced cropping of black borders from stitched panorama.\n",
    "    Uses contour detection and minimum area rectangle to remove all black regions.\n",
    "    \"\"\"\n",
    "    # Create a threshold to identify non-black pixels\n",
    "    # Use threshold=10 instead of 1 to account for very dark pixels and compression artifacts\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    # Apply morphological operations to clean up the mask\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Find contours - should get the main content area\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if not contours:\n",
    "        print(\"Warning: No content area found. Returning original image.\")\n",
    "        return img\n",
    "    \n",
    "    # Find the largest contour (should be our panorama content)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # OPTION 1: Use simple bounding rectangle (fastest but may include some black areas)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    cropped = img[y:y+h, x:x+w]\n",
    "    \n",
    "    # OPTION 2: For more precise cropping, use rotated minimum area rectangle\n",
    "    # Find minimum area rectangle that fits the content\n",
    "    rect = cv2.minAreaRect(largest_contour)\n",
    "    box = np.int32(cv2.boxPoints(rect))\n",
    "    \n",
    "    # Get the corners of the rectangle\n",
    "    (topy, topx) = (np.min(box[:,1]), np.min(box[:,0]))\n",
    "    (boty, botx) = (np.max(box[:,1]), np.max(box[:,0]))\n",
    "    \n",
    "    # Ensure we don't go out of bounds\n",
    "    topx = max(0, topx)\n",
    "    topy = max(0, topy)\n",
    "    botx = min(img.shape[1], botx)\n",
    "    boty = min(img.shape[0], boty)\n",
    "    \n",
    "    # Crop using the rectangle\n",
    "    precise_crop = img[topy:boty, topx:botx]\n",
    "    \n",
    "    # Create inverse mask to find black areas inside the cropped region\n",
    "    inv_thresh = 255 - thresh[topy:boty, topx:botx]\n",
    "    \n",
    "    # Find contours in the inverse mask (these are the black regions)\n",
    "    inner_contours, _ = cv2.findContours(inv_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Initialize boundaries\n",
    "    x0, y0 = 0, 0\n",
    "    x1, y1 = precise_crop.shape[1], precise_crop.shape[0]\n",
    "    \n",
    "    # Analyze contours at the borders to further refine the crop\n",
    "    for c in inner_contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        \n",
    "        # Left border black region\n",
    "        if (x == 0) and (h > w):\n",
    "            x0 = max(x0, w)\n",
    "        # Right border black region\n",
    "        elif ((x + w) == precise_crop.shape[1]) and (h > w):\n",
    "            x1 = min(x1, x)\n",
    "        # Top border black region\n",
    "        elif (y == 0) and (w > h):\n",
    "            y0 = max(y0, h)\n",
    "        # Bottom border black region\n",
    "        elif ((y + h) == precise_crop.shape[0]) and (w > h):\n",
    "            y1 = min(y1, y)\n",
    "    \n",
    "    # Final crop removing any border black regions\n",
    "    final_crop = precise_crop[y0:y1, x0:x1]\n",
    "    \n",
    "    print(f\"Original dimensions: {img.shape[:2]}\")\n",
    "    print(f\"Cropped dimensions: {final_crop.shape[:2]}\")\n",
    "    \n",
    "    return final_crop\n",
    "\n",
    "def stitch_images(image_paths, output_path, display=True):\n",
    "    \"\"\"\n",
    "    Main function to stitch multiple images into a panorama\n",
    "    \"\"\"\n",
    "    # Load all images\n",
    "    images = load_images(image_paths)\n",
    "    \n",
    "    if len(images) < 2:\n",
    "        print(\"Need at least 2 images to create a panorama.\")\n",
    "        return None\n",
    "    \n",
    "    # Start with the first image as the base panorama\n",
    "    panorama = images[0]\n",
    "    \n",
    "    # Process image pairs sequentially\n",
    "    for i in range(1, len(images)):\n",
    "        print(f\"Stitching image {i+1}/{len(images)}...\")\n",
    "        \n",
    "        # Current image to stitch with the panorama\n",
    "        img_current = images[i]\n",
    "        \n",
    "        # Convert images to grayscale for feature detection\n",
    "        img1_gray = cv2.cvtColor(panorama, cv2.COLOR_BGR2GRAY)\n",
    "        img2_gray = cv2.cvtColor(img_current, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect and match features\n",
    "        kp1, kp2, good_matches = detect_and_match_features(img1_gray, img2_gray)\n",
    "        \n",
    "        if len(good_matches) < 4:\n",
    "            print(f\"Warning: Not enough good matches found between panorama and image {i+1}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Estimate homography\n",
    "        H = estimate_homography(kp1, kp2, good_matches)\n",
    "        \n",
    "        if H is None:\n",
    "            print(f\"Warning: Could not estimate homography for image {i+1}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Warp and stitch\n",
    "        panorama = warp_and_stitch(panorama, img_current, H)\n",
    "\n",
    "    # Save the uncropped panorama (with black regions)\n",
    "    # Create uncropped output path by adding \"_uncropped\" before the file extension\n",
    "    base_name, ext = os.path.splitext(output_path)\n",
    "    uncropped_output_path = f\"{base_name}_uncropped{ext}\"\n",
    "    cv2.imwrite(uncropped_output_path, panorama)\n",
    "    print(f\"Uncropped panorama saved to {uncropped_output_path}\")\n",
    "    \n",
    "    # Display the uncropped panorama if requested\n",
    "    if display:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.imshow(cv2.cvtColor(panorama, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Panorama (Uncropped)\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Crop black borders for the final version\n",
    "    cropped_panorama = crop_black_borders(panorama)\n",
    "    \n",
    "    # Save the cropped panorama\n",
    "    cv2.imwrite(output_path, cropped_panorama)\n",
    "    print(f\"Cropped panorama saved to {output_path}\")\n",
    "    \n",
    "    # Display the cropped panorama if requested\n",
    "    if display:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.imshow(cv2.cvtColor(cropped_panorama, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Panorama (Cropped)\")\n",
    "        plt.show()\n",
    "    \n",
    "    return cropped_panorama\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with actual image paths\n",
    "    image_paths = [\"./resources/first.png\", \"./resources/second.png\"]\n",
    "    output_path = \"./resources/panorama_output_1.jpg\"\n",
    "    \n",
    "    stitch_images(image_paths, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2: Using cv2.createSticher function or cv2.Sticher_create function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_images(image_paths):\n",
    "    \"\"\"\n",
    "    Load images from the specified file paths\n",
    "    \n",
    "    Args:\n",
    "        image_paths (list): List of file paths to input images\n",
    "        \n",
    "    Returns:\n",
    "        list: List of loaded images as NumPy arrays\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Warning: Image {path} does not exist. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image {path}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        images.append(img)\n",
    "    \n",
    "    return images\n",
    "\n",
    "def create_stitcher(try_use_gpu=False):\n",
    "    \"\"\"\n",
    "    Create a cv2.Stitcher object with version compatibility\n",
    "    \n",
    "    Args:\n",
    "        try_use_gpu (bool): Whether to try using GPU for stitching\n",
    "        \n",
    "    Returns:\n",
    "        cv2.Stitcher: A Stitcher object\n",
    "    \"\"\"\n",
    "    # Check OpenCV version for proper Stitcher creation\n",
    "    return cv2.Stitcher_create(int(try_use_gpu))\n",
    "\n",
    "def get_status_message(status):\n",
    "    \"\"\"\n",
    "    Convert stitcher status code to human-readable message\n",
    "    \"\"\"\n",
    "    # Handle different OpenCV versions\n",
    "    if hasattr(cv2, 'Stitcher_OK'):\n",
    "        status_dict = {\n",
    "            cv2.Stitcher_OK: \"Stitching successful\",\n",
    "            cv2.Stitcher_ERR_NEED_MORE_IMGS: \"Error: Need more images\",\n",
    "            cv2.Stitcher_ERR_HOMOGRAPHY_EST_FAIL: \"Error: Homography estimation failed\",\n",
    "            cv2.Stitcher_ERR_CAMERA_PARAMS_ADJUST_FAIL: \"Error: Camera parameter adjustment failed\"\n",
    "        }\n",
    "    else:\n",
    "        status_dict = {\n",
    "            cv2.Stitcher.OK: \"Stitching successful\",\n",
    "            cv2.Stitcher.ERR_NEED_MORE_IMGS: \"Error: Need more images\",\n",
    "            cv2.Stitcher.ERR_HOMOGRAPHY_EST_FAIL: \"Error: Homography estimation failed\",\n",
    "            cv2.Stitcher.ERR_CAMERA_PARAMS_ADJUST_FAIL: \"Error: Camera parameter adjustment failed\"\n",
    "        }\n",
    "    \n",
    "    return status_dict.get(status, f\"Unknown error: Status code {status}\")\n",
    "\n",
    "def create_panorama(image_paths, output_path='panorama_output.jpg', try_use_gpu=False, display=True):\n",
    "    \"\"\"\n",
    "    Create a panoramic image by stitching multiple images together\n",
    "    \n",
    "    Args:\n",
    "        image_paths (list): List of paths to input images\n",
    "        output_path (str): Path where output panorama will be saved\n",
    "        try_use_gpu (bool): Whether to try using GPU for stitching\n",
    "        display (bool): Whether to display the result\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: The panoramic image if successful, None otherwise\n",
    "    \"\"\"\n",
    "    # Load input images\n",
    "    print(f\"Loading {len(image_paths)} images...\")\n",
    "    images = load_images(image_paths)\n",
    "    \n",
    "    if len(images) < 2:\n",
    "        print(\"Error: At least two valid images are required for stitching.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Stitching {len(images)} images...\")\n",
    "    \n",
    "    # Create a stitcher\n",
    "    stitcher = create_stitcher(try_use_gpu)\n",
    "    \n",
    "    # Perform stitching\n",
    "    status, panorama = stitcher.stitch(images)\n",
    "    \n",
    "    # Check if stitching was successful\n",
    "    status_message = get_status_message(status)\n",
    "    print(status_message)\n",
    "    \n",
    "    if status != 0:  # 0 is OK in all OpenCV versions\n",
    "        return None\n",
    "    \n",
    "    # # Save the result\n",
    "    # cv2.imwrite(output_path, panorama)\n",
    "    # print(f\"Panorama saved to {output_path}\")\n",
    "    \n",
    "    # # Display the result if requested\n",
    "    # if display:\n",
    "    #     # Convert BGR to RGB for display in matplotlib\n",
    "    #     panorama_rgb = cv2.cvtColor(panorama, cv2.COLOR_BGR2RGB)\n",
    "    #     plt.figure(figsize=(12, 8))\n",
    "    #     plt.imshow(panorama_rgb)\n",
    "    #     plt.title(\"Panorama Result\")\n",
    "    #     plt.axis('off')\n",
    "    #     plt.show()\n",
    "    \n",
    "    # return panorama\n",
    "\n",
    "    # Save the uncropped panorama (with black regions)\n",
    "    # Create uncropped output path by adding \"_uncropped\" before the file extension\n",
    "    base_name, ext = os.path.splitext(output_path)\n",
    "    uncropped_output_path = f\"{base_name}_uncropped{ext}\"\n",
    "    cv2.imwrite(uncropped_output_path, panorama)\n",
    "    print(f\"Uncropped panorama saved to {uncropped_output_path}\")\n",
    "    \n",
    "    # Display the uncropped panorama if requested\n",
    "    if display:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.imshow(cv2.cvtColor(panorama, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Panorama (Uncropped)\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Crop black borders for the final version\n",
    "    cropped_panorama = crop_black_borders(panorama)\n",
    "    \n",
    "    # Save the cropped panorama\n",
    "    cv2.imwrite(output_path, cropped_panorama)\n",
    "    print(f\"Cropped panorama saved to {output_path}\")\n",
    "    \n",
    "    # Display the cropped panorama if requested\n",
    "    if display:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.imshow(cv2.cvtColor(cropped_panorama, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Panorama (Cropped)\")\n",
    "        plt.show()\n",
    "    \n",
    "    return cropped_panorama\n",
    "\n",
    "def crop_black_borders(img):\n",
    "    \"\"\"\n",
    "    Advanced cropping of black borders from stitched panorama.\n",
    "    Uses contour detection and minimum area rectangle to remove all black regions.\n",
    "    \"\"\"\n",
    "    # Create a threshold to identify non-black pixels\n",
    "    # Use threshold=10 instead of 1 to account for very dark pixels and compression artifacts\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    # Apply morphological operations to clean up the mask\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Find contours - should get the main content area\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if not contours:\n",
    "        print(\"Warning: No content area found. Returning original image.\")\n",
    "        return img\n",
    "    \n",
    "    # Find the largest contour (should be our panorama content)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # OPTION 1: Use simple bounding rectangle (fastest but may include some black areas)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    cropped = img[y:y+h, x:x+w]\n",
    "    \n",
    "    # OPTION 2: For more precise cropping, use rotated minimum area rectangle\n",
    "    # Find minimum area rectangle that fits the content\n",
    "    rect = cv2.minAreaRect(largest_contour)\n",
    "    box = np.int32(cv2.boxPoints(rect))\n",
    "    \n",
    "    # Get the corners of the rectangle\n",
    "    (topy, topx) = (np.min(box[:,1]), np.min(box[:,0]))\n",
    "    (boty, botx) = (np.max(box[:,1]), np.max(box[:,0]))\n",
    "    \n",
    "    # Ensure we don't go out of bounds\n",
    "    topx = max(0, topx)\n",
    "    topy = max(0, topy)\n",
    "    botx = min(img.shape[1], botx)\n",
    "    boty = min(img.shape[0], boty)\n",
    "    \n",
    "    # Crop using the rectangle\n",
    "    precise_crop = img[topy:boty, topx:botx]\n",
    "    \n",
    "    # Create inverse mask to find black areas inside the cropped region\n",
    "    inv_thresh = 255 - thresh[topy:boty, topx:botx]\n",
    "    \n",
    "    # Find contours in the inverse mask (these are the black regions)\n",
    "    inner_contours, _ = cv2.findContours(inv_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Initialize boundaries\n",
    "    x0, y0 = 0, 0\n",
    "    x1, y1 = precise_crop.shape[1], precise_crop.shape[0]\n",
    "    \n",
    "    # Analyze contours at the borders to further refine the crop\n",
    "    for c in inner_contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        \n",
    "        # Left border black region\n",
    "        if (x == 0) and (h > w):\n",
    "            x0 = max(x0, w)\n",
    "        # Right border black region\n",
    "        elif ((x + w) == precise_crop.shape[1]) and (h > w):\n",
    "            x1 = min(x1, x)\n",
    "        # Top border black region\n",
    "        elif (y == 0) and (w > h):\n",
    "            y0 = max(y0, h)\n",
    "        # Bottom border black region\n",
    "        elif ((y + h) == precise_crop.shape[0]) and (w > h):\n",
    "            y1 = min(y1, y)\n",
    "    \n",
    "    # Final crop removing any border black regions\n",
    "    final_crop = precise_crop[y0:y1, x0:x1]\n",
    "    \n",
    "    print(f\"Original dimensions: {img.shape[:2]}\")\n",
    "    print(f\"Cropped dimensions: {final_crop.shape[:2]}\")\n",
    "    \n",
    "    return final_crop\n",
    "    \n",
    "# List of image paths for stitching\n",
    "image_paths = [\n",
    "    \"./resources/1.jpg\",\n",
    "    \"./resources/2.jpg\",\n",
    "    \"./resources/3.jpg\",\n",
    "    \"./resources/4.jpg\"\n",
    "]\n",
    "\n",
    "# Comment out the following line to avoid immediate execution\n",
    "panorama = create_panorama(image_paths, output_path=\"./resources/panorama_result.jpg\", try_use_gpu=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
